
# 以太坊扩容方案调研报告
课程作业，比较naive，如有错漏欢迎批评指正


## 一、摘要
区块链作为一种需要达成共识的分布式账本，在性能上来讲弱于传统的中心化数据库。随着区块链的用户量逐渐增大，性能的瓶颈越来越限制区块链的发展。这导致了交易费的飙升，限制TPS的性能问题亟需解决。因此，越来越多的区块链扩容方案被提出，包括对于区块链本身结构/算法进行修改的链上扩容方案、将部分计算放在链外的链下扩容方案等等。本调研报告将主要对于以太坊的扩容方案进行调研，针对各种扩容方案，比较其原理、优缺点、适用范围、当今发展状况等等，同时结合模块化的区块链设计与以太坊的发展路线图概览，希望对于以太坊的扩容方案现状及未来有一个全面的认识和思考。
## 二、引言
区块链[1] 是一种分布式账本技术，通过密码学与共识协议等技术实现了一个去中心化、不可篡改的账本系统。从2008年比特币[2]出现以来区块链的普及程度逐渐增加，使用加密货币和开发区块链相关应用的人越来越多。2013年以太坊[3]的出现更是预示着正式进入区块链的2.0时代。开发者可以更容易地在区块链上使用智能合约创建他们的应用并提供给用户使用；而用户也可以通过各种各样的Dapp（去中心化应用）来在区块链世界进行更多的交互，体验更加丰富的功能；加密世界的前景不可估量。

然而，随着区块链用户的增多，加密货币价格飞速上涨。根据coinbase交易所的数据[4]，在2022年四月，比特币的价格最高达到四万五千美元，以太坊价格最高达到4000多美元，而这离历史最高价格还有不小差距。随着价格的增长，加密货币的交易费用也不断增加。以太坊上一个简单的转账就要花费几美元的gas（汽油）费[图1]，而进行智能合约的调用则更加昂贵；在opensea网站[5]上购买一个NFT（非同质化代币）的花费高达十几甚至几十美元。而对于更加复杂和频繁场景的合约调用，其开销更是令人难以承受。以区块链游戏为例，如果区块链游戏与日常网络游戏一样需要频繁跟服务器进行通信，甚至在部分即时游戏中一秒都要同步几十次，那花销将会无法估计，同时性能也无法满足。现在的区块链游戏大多都选择将游戏数据存在本地缓存，而只有在需要互动（购买、战斗）等场景时才上链交互，尽可能减少交互次数；然而即便如此，如果游戏部署在以太坊上，那经常二三十美元的花销也是远远不可承受的，因为与之相比很多3A游戏大作的买断价格也才几十美元。总之，以太坊上的高价gas费已经成为了明显阻碍其发展的一个因素，以太坊甚至因此被称为是“贵族链”。这与加密世界的去中心化和开放精神都是相违背的。


另一方面，高昂的gas费不仅仅是因为币价的上涨，也有很大程度是因为以太坊的TPS（Transaction Per Second, 每秒交易数）太低。以太坊的出块速度大约是10秒钟，而每个块通常包含几十到几百个交易。也即以太坊的TPS大约只有50以内。这样的速度远远低于任何传统互联网服务的容量，因此为了提供服务自然需要不停提高费用，这也是导致以太坊gas费用水涨船高的原因。
<center>
    <img src=https://i.imgur.com/vpDZvnK.png>
    <center>
        <p>图1.一笔简单的转账,花费将近3美元</p>
    </center>
    

    
</center>


然而这个问题的解决方案却并不直观。类似于传统分布式系统，区块链也有不可能三角问题[图2]：可扩展性（Scalability），安全性（Security）和去中心化（Decentralization）三者中，最多只能同时实现两种。因此，对于可扩展性的提高或多或少都意味着对于另外两者的下降。尽管如此，可扩展性现在已经越来越成为限制以太坊发展的头号问题，因此以太坊创始人Vitalik也表示可扩展性应当是以太坊目前遇到问题中排名第一的。
<center>
    <img src=https://i.imgur.com/AXdVWGI.png>
    <center>
        <p>
            图2.区块链不可能三角，来源Vitalik
        </p>
    </center>
</center>



为了解决这一问题，众多的以太坊扩容方案被提出并实施，并且已经出现了许多相对成熟且应用广泛的产品。扩容方案大致可以分为两类，一类是链上扩容：也即在原始链上进行一些改变来使得链上达成共识的速度更快、包含更多的交易，同时不损失安全性；另一类是链下扩容方案，即并不将原始交易直接放在链上进行，而是放在其他地方，最后统一通过以太坊来进行提交和验证。在两种方案中，许多链上扩容方案已经在以太坊的roadmap（路线图）中并且即将上线，而众多链下扩容方案也由多种多样的协议实现了不同的产品并且现在应用十分广泛。

在本调研报告中，首先将针对不同的扩容方案在原理、产品和前景等等方面进行简要分析，对于各种方案进行汇总和思考。之后，从整体的角度来看以太坊未来发展的趋势以及扩容路线图，如何在多种扩容方案中进行选择并结合到一起真正提高以太坊的运行效率和使用体验。
## 三、链上扩容
链上扩容方案实际上多种多样，最直观的方式就是把区块大小限制增加从而能够容纳更多的交易，或者把挖矿难度降低从而减少出块时间。然而，加大区块大小会显著增加运营全节点的压力，从而使得中心化程度更高。比特币曾经就因为区块大小有过分叉，包括BCH和BSV；但是在压力测试中，BCH有16%节点掉线，BSV更是引起了很多区块的重组。显然这样简单粗暴的方式并不是那么容易实现的。

### 1. 分片（Sharding）
#### 原理
分片实际上是从传统计算机科学中学习来的解决方式。在数据库中，分片是一种很常见的容量问题解决方案[7]，通常分为水平切分和垂直切分两种方式。水平切分（horizontal partitioning）即将一个表里面不同的行，切分到不同的表；每一个表内的每条记录仍然是完整的、独立于其他表的。而垂直切分（vertical partitioning）则是将每行不同的列切分到不同的表中。两种切分方式的差别可以见下图3.
<center>
<img src=https://i.imgur.com/Vjd56k2.png>
    <center>
        <p>
            图3. 两种数据库分片类型
        </p>
    </center>
</center>

以太坊的分片采用的是类似于水平切分的思想。在现在的以太坊中，每一个全节点都需要对一个区块内所有的交易进行验证，这不但在运行效率上有所影响同时也会受到网络延迟的影响。分片即把以太坊的历史和状态数据进行切分，每一个分片仅负责储存部分的数据并进行验证，从而使得每个节点承担的执行和网络压力都变小，来提高整个网络的运行效率。

在分片之后，网络节点的划分与现在有所不同。将会有部分超级节点来负责信标链的运行、以及验证者的分配；而现在的绝大多数“矿工”将作为单分片节点运行，只负责自己所属分片中节点的验证。轻节点将只维护主链上的数据，只有在特别需要访问某个分片数据的时候才会下载。


#### 发展现状
分片是以太坊发展路线中非常重要的一个组成部分，为下一代的以太坊共识提供了重要的基础。根据以太坊2.0的roadmap[10]，阶段0是单纯的PoS信标链(Beacon Chain)，使用Casper FFG的PoS共识协议；在阶段1，基本的分片上线；之后对于协议的安全性和与以太坊1.0的关联不断扩充；在阶段4上线跨分片的交易；而在阶段6也有exponential sharding等计划。在以太坊3.0的暂时规划中，也有看到与异质化分片相关的内容。
可以看到分片、PoS、信标链等等机制相互结合共同构成了以太坊2.0的高效共识协议，分片的更新发展也一直存在与以太坊的发展规划之中，可以认为区块链分片终将会是未来。在现在的一些其他公链上，比如ICP（Internet Conputer Protocol）上，尽管与以太坊生态完全不同，但是也有了类似于分片的结构从而使得运行效率更高开销更低。然而现在以太坊的整体更新进度还比较缓慢，分片还需要长时间的发展。

### 2. 其他方案
还有一些其他链上扩容方案可以使用，包括状态休眠机制（state expiry）和维克尓树（Verkel tree）等等。状态休眠机制即移除那些长久没有被访问过的状态，从而使以太坊的存储状态减小；维克尓树可以实现只有矿工存储他挖出的块，其他节点可以无状态地进行验证。这些方案同样都是属于扩容方案的其中一部分，我们会在后续简单提及。
## 四、链下扩容
这里的链下相对于链上扩容而言，是指以太坊链之外进行一些扩展，而不是指完全不依赖于区块链或者以太坊。传统的链上扩容方案通常被称为Layer 1（L1）方案，也即是在以太坊本身上面进行的修改；而链下扩容则通常被称为Layer 2（L2）方案。在Layer2方案中，区块链更加具有模块化：相比于之前所有功能都集中在以太坊主链，现在以太坊主链仅仅充当共识安全性的保证，而数据的执行层则放在了Layer2上。这也就意味着，如果L2宕机，L1依然可用并且数据依然保持完好；但是如果L1受到攻击，则整个系统安全性会崩溃，L2也不再可用。在底层的区块链搞非常复杂的结构不是一个好方法。layer1应该保持最小程度的简洁和稳定，每添加一个功能都应该非常小心，而大量复杂的特性应该放在底层区块链之外进行解决，也即layer2。这也阐述了Layer2的必要性以及为什么它现在如此流行。
根据[11]，L2方案大致可以按照如下方式分类。首先是根据所使用的加密性证明方案划分，也即证明交易的有效性的方法，现在通常包括有效性证明和欺诈证明两种方式。有效性证明即通过零知识证明（ZK，Zero Knowledge）的方式证明交易的有效性，而欺诈证明则是引入争议时间延迟（DTD），验证者可以验证某个交易是无效的，回滚并且给予一定的惩罚。第二种分类方式是数据可用性（DA, Data Accessibility）在链上还是链下。链上方案是将L2所有的交易相关数据全部打包进calldata放在链上，使得其可以被验证；而链下方案则是将大部分的calldata都放在链下，这导致了不够安全和去中心化，但却能够在同一次打包更多的交易数据。
根据以上两种分类方式，可以对于主流四种Layer2方案进行分类，如下图4（来自[11]）:
<center>
    <img src=https://i.imgur.com/TXIZE59.png>
    <center>
        <p>
            图4. Layer2方案分类
        </p>
    </center>
</center>

在之后，我们会分别对于这四种方案进行阐述。同时，还有一些相对早期或者并不主流的方案，包括状态通道（State Channel）和侧链（Side Chain）。这两种方案是否能够被称作Layer2，甚至是否被算作以太坊扩容方案都有一定的争议，我们会对于其中的部分方案进行简单讨论。
### 1. State Channels
状态通道可以认为是最早的扩容方案。其适用场景为双方的高频交易，通过在链下全部交易完成后数据上链，双方签名打包后链上结算。通常来说，其实现为一个链上的多签智能合约，双方把一定的金额存在合约内部，最后通过向合约提交总体交易列表并且双方签名来取回各自的钱[24]。
其优缺点也均非常明显。优点是安全性完全由layer1来保证，能够由非常高的TPS并且在主网及时清算，且在高频交易情况下大大降低gas费用。其缺点也是受限于适用场景，仅仅在只有少数几方参与并且高频交易时才可以使用，不支持开放式交易，如果交易频次低可能gas费用比直接交易还要高。也是因为以上明显的缺点，状态通道方案仅在一些应用中的部分功能进行使用，并不能真正算是扩容方案。
### 2. Plasma
Plasma[31]最早由 Vitalik Buterin 和 Joseph Poon 在 2017 年提出，可以认为是最早的主流Layer2方案。它的大致设计为创建了一条新的子链，可以将主链的资产质押从而获得在子链的资产，也可以将子链资产提取回主链。而在子链上我们可以进行各种交易，并通过欺诈证明的方式保证子链交易的安全可信。
#### 原理
整个Plasma机制的核心实际上就在如何子链与主链保持同步这一方面，包含了退出和挑战两个核心机制[12]，而其底层实现主要是基于智能合约和默克尔树。在主链上，Plasma协议实际上就是一个智能合约，可以接受转账来把钱兑换到子链使用，也可以从子链提现到主链拿回ETH。除此之外，子链实际上是一条单独的区块链而没有任何限制，它可以由各种各样的共识协议（PoW，PoS，PoA等等）以及各种各样的结构，而这些交易信息大部分都不需要同步到主链，而只需要提交默克尔树的根哈希等等少量数据，这使得在主链上的相关数据很少从而大大降低了成本。
关键点在于，当一个用户发现子链作恶时，也即产生了一个假的区块，他可以提交一个欺诈证明到主链，证明这笔交易时作恶的，从而对这个区块的记账者（验证者）进行惩罚而没收其在主链上的资产，并且状态回滚到上一个可信的区块。即使用户无法提供证明，但是感觉子链有可能作恶，Plasma也有Safe exit的机制，可以通过用户提供他的最后一个信任区块状态来把资金撤回到主链上，从而保证子链资金的安全。
Plasma的优点是显而易见的。它的确起到了提高可扩展性的作用，加快交易速度并降低交易费用，同时大大减少了主链存储的数据量；而且Plasma协议本身对于子链的限制很少，各种结构、共识、分片的子链都可以在Plasma协议上进行构建，灵活性很强，同时还可以树状结构构建无限多个子链来进行无限扩展。
然而，其缺点也和优点一样明确。首先欺诈证明在安全性上确实不如有效性证明，它需要用户时刻关注自己是否遭到欺诈并且及时提出挑战；同时，在与主链交互时需要有非常长的挑战期，这使得取钱变得异常困难，尤其是对于小资金的用户而言。
#### 发展状况
2017年Plasma被提出后，被认为是及其成功的扩容方案，甚至当时其宣传能够无限进行扩容。然而在今天，Plasma似乎已经走向死亡[13]，几乎没有主流生态在使用Plasma技术，以往使用Plasma的团队也纷纷转向了更新的一些rollup系列的解决方案。我们可以回顾Plasma生态和产品的发展历程来一窥究竟。
最初走向实用的Plasma方案是MVP（Minimal Viable Plasma），对于Plasma原始协议进行了进一步的明确与简化，使用UTXO机制的侧链。在2017年市场火热的时间段，大家对于Plasma异常狂热，相信它的安全机制和强大的可扩展性。然而，在2018年熊市到来时，大量用户的退出引发了MVP的问题；一方面很长的挑战期让资金难以退出，另一方面提交退款证明也需要提交自己最后保留的子链状态，这让本就拥堵的以太坊主链进一步崩溃；这一现象也类似于人群的踩踏行为，状况越混乱就有越多的人选择退出，从而使得问题彻底爆发。
在此之后，为了解决以上问题，新的名为Plasma Cash的解决方案被提出，主要是希望解决每个人都要时刻维持子链全部状态来提供欺诈证明的问题。每个人的资产被作为NFT存储起来。当运营商有可能欺诈时，用户只需要证明自己对于资产的所有性即可，大大简化了流程；然而仍然可能有恶意用户或者过去的代币所有者欺诈，所以仍然需要用户在每个挑战期内都在线来维护自己的资产；同时为了维护所有权，用户仍然需要维持很多过去状态，对于用户来说很不友好。
在Plasma Cash以外，还有Plasma Debt、Plasma Leap等等产品/协议被创作出来，但是整个基于Plasma的生态仍然没有反弹，一直处于低谷直到后续我们提到的rollup系列方案出现。
总的来看，Plasma可以认为是二层扩容的第一个尝试。它的设计初衷是好的，并且在原理上也的确能够满足安全性和无限可扩展性的要求。然而在现实场景下，过度追求减少链上数据减小以及降低gas费反而会使得用户体验下降严重，并不能成为一个实用的二层协议。协议在设计时需要在多方面做到平衡，毕竟最终的目的还是为了让用户能更轻便快捷使用链上应用。
### 3. Rollup
从上述部分我们可以看到，Plasma是一个“完全的”Layer2方案，它将大部分内容全部移到了链下，仅仅在最基本的资金安全上与链进行交互；这种方案完全靠用户来掌握子链的状态，这使得这种方案很难适用于所有的加密用户[14]。
在2018年，一种叫做Rollup的方案被提出。相比于Plasma这种将全部内容移到线下的方案，Rollup系列方案是一种“混合型”的Layer2方案。它仅仅把计算移到了线下，而只在主链上存储最少量的交易数据来保证安全，从而能够指数级提高TPS。这种方案把在Layer2链上的交易打包（roll up）起来上链，在以太坊上进行存储和验证正确性。那么根据在以太坊上如何进行交易的验证，rollup可以分为两种方案：通过零知识证明证明正确性的ZK-Rollup系列方案，和通过欺诈证明来保证正确性的Optimistic Rollup系列方案。
从去年开始，以太坊进入了以rollup为中心的发展路线。EIP-4488[15]的提出，正是为了减小calldata部分所消耗的gas费用，为各种rollup方案的打包提供便利。可以说，rollup是解决以太坊Layer2问题的终极方案。
#### ZK rollup
ZK rollup顾名思义，是使用零知识证明的方案对于打包交易进行证明。一个ZK rollup方案由两部分组成，一部分是运行在Layer1上，也即主链上的智能合约，而另一部分则是在Layer2运行的链。主链智能合约的作用是经常与Layer2链进行通信，获取打包后的交易及其证明，对于证明进行验证后将数据打包上链（通常只有默克尔树的根等部分，并不是全部上链）；而Layer2链的功能就是执行大量的交易，将交易打包成一个block之后生成零知识证明并且提交到主链。其运行过程可以大致参考下图5、6.
<center>
    <img src=https://i.imgur.com/UHchzGI.png>
    <img src=https://i.imgur.com/RQ0ebNd.png>
    <center>
        <p>
            图5及图6. ZK rollup执行过程
        </p>
    </center>
</center>

在此对于零知识证明相关技术进行一定的补充。零知识证明，即在证明某个命题的同时不提供除了正确性以外的任何信息，例如著名的百万富翁问题[16]，即两个人希望在不透露自己的资产具体有多少的情况下，比较出两人拥有资产的多少；或者向某人证明自己知道某个哈希的原像，但是不透露任何关于原像的信息等等。在上述问题中，我们大多数采用的是交互式零知识证明(Interactive Zero Knowledge Proof)，需要证明者（Prover）和验证者（Verifier）进行多轮交互来完成证明。然而在区块链使用场景中，我们为了减少链之间通信的巨大开销和低性能，使用的是非交互式零知识证明，也即只需要证明者提供一段证明，然后验证者就可以验证证明的正确性。通常使用的方案有zkSNARK和zkSTARK等。zkSNARK仍然是现在运用最广泛的零知识证明方案，也相对更加简洁，但是缺点是需要trusted setup，也即需要可信的初始参数设置，否则很容易作恶；同时zkSNARK生成的证明大小在交易数量增多的情况下呈指数级增长。zkSTARK即针对以上方案做出的改进，其中的T即Transparent，表示其不需要可信初始设置即可工作；同时证明大小随交易数量的增长是线性的。近些年来，也有一些其他的零知识证明方案被提出，包括bulletproof等，但是在Layer2投入使用的部分较少。相关效率比较参考图7[17]：
<center>
<img src=https://i.imgur.com/Tjtymkc.png>
    <center>
        <p>
            图7. 不同零知识证明方案效率比较
        </p>
    </center>
</center>

上述的零知识证明方案都是针对的多项式，也即证明某个多项式成立，因此在执行中我们需要把程序字节码执行的证明转换为一个多项式等式。而尽管EVM是一个图灵完备的虚拟机，但直接在其上实现一个零知识证明的方案将会非常复杂并且耗费大量gas，因此现在主流的zk rollup方案都是使用电路来生成证明，同时有一些对于支持zk的硬件也在开发中。生成零知识证明是一个非常耗费算力的工作，而验证它则非常简单，未来可以将生成证明的工作打包给矿工来进行。同时，现在的主流zk rollup方案都非常有限，基本都还无法做到完全兼容EVM，这也就使得在现阶段zk rollup型layer2的产品中开发各种DApp都非常受限。

为了解决上述问题，一种方案是构造ASIC（Application Specific Circuit, 应用专用电路）来使得指定的DApp能都运行，这需要开发者针对不同的DApp设计不同的ASIC电路，对于开发者来说是一个较大的负担同时门槛比较高，但这也是目前在zk rollup二层方案上写应用最常见的做法。而现在最新的zk rollup方案开始尝试搭建zkEVM，也即完全与EVM相兼容的Layer2扩容方案。如果能够实现，则可以将目前eth主链上的智能合约不经修改直接迁移到二层网络上，同时大大提高效率和降低手续费。

尽管zk rollup的发展还在相对早期，还没有zkEVM的项目进入主网阶段，但是使用该技术的扩容方案仍然在市场相对火热。比如开源的zkSync，基本上是zk rollup方案的最早期进入者，其设计大致如图8所示。
<center>
<img src=https://i.imgur.com/QzdATnH.png>
    <center>
        <p>
            图8. zkSync执行流程
        </p>
    </center>
</center>

可以看到，图8基本符合我们上面对于zk rollup系统的描述。zkSync的优势在于开源、不需要可信任的基础设置(trusted setup)以及gas费用低，其上的交易数量和金额也与日俱增，市场对其兴趣浓厚。其他还有包括StarkWare开发的基于zkSTARK的扩容方案，以及Loopring针对于交易开发的二层网络，都在市场上十分活跃并且有众多开发者参与。


综上来看，zk rollup系列方案作为最早出现的rollup系列方案，实际上能够比较完美地达到扩容的目的。而其缺点主要是生成证明十分耗费算力，以及无法简洁地像在一层网络上一样书写DApp。当这两个问题都解决之后，zk rollup会成为一个十分优秀的扩容方案。

#### Optimistic Rollup
由于zk rollup技术过于复杂并且短期内难以与以太坊完全兼容，一种新的更加简洁的rollup方案被提出，也即Optimistic rollup。两种rollup技术的简单比较可以参考下图9[18]
<center>
<img src=https://i.imgur.com/W5Jug3l.png>
    <center>
        <p>
            图9. Optimistic Rollup与ZK Rollup对比
        </p>
    </center>
</center>

可以发现，相比于zk rollup的提交交易证明，optimistic只提交交易相关的数据，并且使用欺诈证明的方式来保证交易数据的正确性。Optimistic可以被认为是结合了zk rollup和Plasma各自的一部分特性构造出来的暂时解法，其名字的含义也就是乐观地认为所有打包者都是善意的，而使用欺诈证明对于恶意的验证者进行惩罚。

而Optimistic rollup的一个核心技术，就在于OVM（Optimistic Virtual Machine）。OVM是在二层网络中执行交易的环境。可以认为OVM是Layer2特化版的EVM。用一个不太恰当的比喻来讲，OVM与EVM的关系类似于Docker与物理计算机的关系。有了OVM，我们就能更加简洁地将已有的Layer1智能合约部署到二层网络上，这对于开发者更加友好。

OVM需要实现的功能是，在EVM上也能够执行OVM中执行的指令。这样，当有人提出欺诈证明，主链上的合约就可以用EVM重放Layer2当时的那笔交易来进行正确性验证。那么OVM与EVM的区别在哪里，为什么不可以直接使用EVM来进行欺诈证明呢？一个错误的实例为以下合约[19]：
```solidity=
contract TimeShifter {
   function getShiftedTime() returns(uint) {
      return block.timestamp + 42;
   }
}
```
当尝试在主链重放以上合约时，由于当前主链的时间戳与原始合约执行时的时间戳并不一致，两次执行的结果必然不同，而这会在合约正确的情况下得到不一致的执行结果从而使得交易被误认为欺诈。为了解决这一问题，OVM引入了一个新的智能合约执行管理器（Execute Manager），要求所有类似于时间戳这种会引起执行不一致的代码都通过管理器进行调用。容器如下构造：
```solidity=
contract TimestampManager {
    uint storage ovmTimestamp;

    function setOvmTimestamp(number: uint) {
        ovmTimestamp = number;
    }

    function getOvmTimestamp() public returns(uint) {
        return ovmTimestamp;
    }
}

```
通过这个容器，我们即可将以上代码重构成：
```solidity=
contract OvmTimeShifter {
   function getShiftedTime() returns(uint) {
      return timestampManager.getOvmTimestamp() + 42;
     }
}
```
从而保证代码在两套执行环境中的结果一致。而为了防止用户误用原始timestamp进行编写，OVM还提供了纯度检查以及转译器。纯度检查用来检查合约中没有涉及到需要被虚拟化的指令，而转译器可以将EVM上的代码直接转换成OVM代码。这大大方便了开发者在Layer2上进行开发，只需要仍然使用solidity等语言编写智能合约并且照常编译部署即可。现在常用的Layer1开发环境包括truffle等等都已经适配和Optimistic的开发环境。

当然，由于使用了欺诈证明的方案，它也在一定程度上具有和Plasma类似的缺点，那就是需要经过很长的挑战期才能够从主链取钱等等。但是由于其与EVM的兼容性极好，能直接运行DApp而不是仅作为交易使用，可能更倾向于成为一个独立的、用Layer1做底层安全性保证的生态环境，这也就让它的缺点显得不那么重要了。

相比于zk rollup系列方案，Optimistic rollup的产品更加主流、适用范围也更广。市场上最流行的Layer2协议Arbitrum和Optimism均为该赛道产品。总而言之，Optimistic的方案在现阶段的确是各方面最优秀、适应性最好的rollup方案。
#### 比较与展望
关于zk rollup与optimistic rollup优劣性的比较，在上文中有所提及，汇总和扩展如下（参考[20]）。
Optimistic rollup的特点在于：
* 每笔交易只需几千gas，理论TPS可以达到几百的级别，足以在大部分情境下应付现在的加密世界交易。
* 需要至少有一个诚实的矿工去验证交易和提交欺诈证明，因为对于普通用户来说对于状态的持续跟踪代价较大。
* （现阶段）更加能进行通用计算，更适合DApp生态。
* 需要长时间的挑战期才能够确认交易

ZK rollup的特点在于：
* 每笔交易仅需几百gas，理论TPS可以达到几千的级别，能够在很长时间内满足需求。
* 通用性计算能力较差，可用产品大多只能进行ERC20转账等等操作，距离完整开发EVM兼容的DApp还有一定距离
* 使用密码学机制来根源上保证安全性，更加符合crypto的精神。
* 对于普通用户来说生成证明时间极长，大大拖慢了交易速度。

rollup系列的方案已经加入以太坊发展路线图，可以认为是以太坊的终极扩容方案了。两种方案相比，大多数人认为Op方案在短期内是最优解，而未来则一定属于zk[21]。Op方案的缺点主要在于很长的挑战期，而我们完全可以通过各种中心化交易所服务进行L2货币到L1的兑换，同时也有一些跨链桥项目在帮助实现这一目标。各种DeFi项目例如Uniswap都可以在OVM上进行实现，这可能会使得Op赛道真正发展起来。而长期来看，ZK不论是在安全性上还是时效性上都是最优解。我们只需要等待完全兼容EVM的方案出现，以及足够的算力/解决方案来加快证明的生成，ZK rollup必将成为未来扩容的最终答案。
### 4. Validium
Validium是对标zk rollup出现的一种方案，希望能与zk rollup进行互补通过零知识证明技术来保证更多需要安全性的使用场景。它由StarkWare公司开发，使用zkSTARK作为证明方案。与zk rollup相比，区别主要在于Validium方案的数据可用性放在链下。这一方面使得交易速度加快，同时更能够保证用户的隐私因为数据并不是在链上公开，但另一方面也增加了额外的信任需求，因为操作者可以对交易进行修改甚至冻结账户。
为了一定程度上避免这一状况，StarkWare引入了数据可用性委员会（DAC），通过较可信的机构进行验证从而某种程度上增加用户的信任。事实上，Validium类方案不应该对标传统Layer2，它更像是一个使用零知识证明保证安全性的传统中心化交易所[22]。因此，zk rollup方案更适合对于数据安全性要求较高的各种交易和应用，而Validium方案更适用于高频的游戏等应用[23]。

## 五、扩容思考：模块化设计
在上文所述的多种扩容方案中，链上扩容方案牺牲了一定的去中心化程度（由于超级节点需要超高的容量和带宽），而Layer2方案又依赖于Layer1的安全性。能够完美彻底解决不可能三角的单一设计是不存在的，因此真正的扩容方案可能需要多种方案的结合。

重新思考不可能三角中的要素以及区块链的组成部分，发现区块链中不同的组成部分能够分别对应其中一些要素[26]：
* 共识机制，保障了安全性和去中心化。尽可能多的低门槛节点能够参与共识才能够保障安全性。
* 执行机制，部分程度上限制了去中心化与可扩展性，正是由于大量交易的执行有困难所以提高了节点的门槛。
* 数据可用性机制，与可扩展性有紧密联系。

因此，在同一条链的设计中同时实现以上几点是不可能的，单片式区块链在扩容需求增加的今天注定要走向失败。而未来的设计注定是模块化的，将共识、执行和数据可用性三者分别设计实现，最后将它们组合起来[27]。每个单独的部分都不可能满足全部三种性质，但组合后的整个系统却在各方面都能达到优秀

### 共识
共识的优化在上文的扩容方案中没有提到，但实际上共识方案从PoW到PoS的转变也是对于扩容很有利的一个提升。PoW由于需要超强的算力来获得记账权，同时还需要很大的内存和硬盘来执行交易并且存储区块数据，这就导致了矿工的中心化程度变高。而在PoS中，任何一台计算机都可以质押ETH从而进行“挖矿”（也即成为验证者）。这一方面实现了数字资产的内部循环，让验证者由数字资产来决定而不是由现实资金购买的“矿机”决定，更有利于加密生态的内生安全；同时低成本的“挖矿”也能够让更多用户参与到验证中来，从而更加能够提高以太坊的容量上限并且提供安全性。
### 执行
在模块化的区块链设计中，执行层完全与上述共识层分离开来。由rollup层提供执行功能，创建一个专注于执行交易的链下执行环境。而其安全性一方面来自于在主链上创建的智能合约，另一方面是基于欺诈证明或者零知识证明等密码学要素。而在主链上的智能合约中，用户可以在rollup链崩溃时将自己的资金安全提取。因此，智能合约和密码学作为桥梁，将L1的安全性桥接到了rollup链上，从而使得rollup链无需再提供任何关于安全性和去中心化的保障。因此，rollup链的运行成本大大降低，仅需少数几个较为中心化的节点进行交易的执行打包和提交即可，这也更有利于性能的提升和各种rollup生态的开发。
### 数据可用性
数据可用性的最大化通过分片来解决。如果按照当前整个主网仅仅有一个分片的情况，所有的矿工，或者说未来的验证者都要保留整个主网的数据并且进行验证，明显过剩，并且这将会成为数据上链很大的负担；也正是因此，现在上链的数据和状态都需要精打细算并且开销昂贵。
分片恰恰是解决这一问题的良方。通过将每一个分片的大小减小以降低验证者的负担，同时用更多的分片来使总容量增加。超强算力和网络的节点则在信标链上负责进行验证者的分配和打乱。经过分片，每个验证者所需要存储的数据减少，同时整个网络的数据存储能力增加；并且随着摩尔定律的发展分片还能够不断扩展，实现最终的数据可用性扩容。

### 综合
PoS, 分片, Layer2，几大技术的结合恰恰是以太坊能够走向未来的关键。这不仅仅是简单地把原本以太坊主链地功能进行拆分，拆分出地几部分能够更加独立地进行发展开发并且相互促进。例如随着PoS验证者池子的扩大，网络中的参与者节点增多，从而能够开辟出更多的分片进行扩容；大量的Layer2产品开发出来促进用户量的增多，更推动了更多的验证者入场来参与验证。

同时更重要的一点是，这些技术的结合能够帮助以太坊更加良性地发展。虽然以太坊目前是加密市场中最主流使用最广泛地货币，但其货币生态系统仍然是不健全的。目前每个区块的货币流出量都小于矿工获得的货币量，即使在加入EIP-1559燃烧后仍然如此，这很大程度是由于现在的网络上限TPS不足。当更多的分片出现，交易数量大大增加，保障燃烧的量与挖矿产出的量相对平衡，更有利于维持整个生态系统的健康。

## 六、以太坊发展路线展望
以太坊的发展路线图一直是以扩容为目的，经过从开始提出到信标链上线，到最近的测试网络合并以及拖了许久仍未上线的分片和PoS，已经走过了相当长的一段路程并且还在不断的更新发展。本部分将结合上述提及的扩容方案以及模块化设计来对于以太坊的发展路线图做一些分析。
### 1. 数据可用性
现在的以太坊发展已经从“以分片为中心”转向了“以rollup为中心”的路线图，这也就意味着执行层在以太坊主链不再作为关键扩展进行研究，而更重要的是提高数据可用性。路线图中的众多方案都是基于这一点进行的提出和实施：
* EIP-4444[28]，限制客户端对于历史数据的存储。现在的每一个客户端都需要保存所有的链上数据，这对于客户端来说成为很大的负担，并且在将来rollup系列发展起来之后数据量进一步增大，更不利于节点的运行。本EIP提议修剪超过一年的历史数据。同时，以太坊尝试转向弱无状态的情况，使得验证区块不需要状态，结合Verkle Tree等机制来实现。
* EIP-4488[29]，减少calldata部分消耗的gas费用，是明显有利于rollup系列方案的一条提案。rollup将执行在链下进行，而将执行后的数据和证明打包上链，这就需要大量数据的传输，而calldata gas费的降低使得这一操作成本降低。
### 2.DankSharding
由于发展中心转向rollup，分片方案也从执行分片转向了数据分片。在前文我们简单叙述了分片的大致思想，而这种设计在未来的以太坊发展中有很大一部分已经废弃。在DankSharding中，验证者执行DAS（数据可用性抽样），不需要下载完整的数据即可保证自己所在分片的数据可用性。在这一过程中，大量技术例如抽样、纠错码，KZG承诺等等来实现这一点，其中的技术细节在此不做展开。
### 3.MEV对抗
MEV，即矿工可开采价值（Miner-Exploitable Value）。简单来讲，由于区块中的交易顺序并不固定，矿工有权通过先打包自己的交易节省gas费用、合约抢跑、套利机器人、甚至秘密操纵某些投票来获取利益。在新的以太坊中，人们家中自己运行的验证者节点可能无法像现在矿工一样捕获这些MEV，因此需要在这一层面进行部分改进，比如通过协议禁止部分恶意MEV，或者由部分节点来负责捕获MEV并且分配给验证者，等等。
### 4. 总结
总体来讲，以太坊的未来将会是中心化的区块产生与执行，加上去中心化的验证[30]。rollup为中心的模块化发展路线从现在的角度看来的确是一个正确的选择，各种保障rollup实施的基础架构改变和EIP也都在不断地完善发展，未来的终点清晰但是路线仍待商讨。

## 七、总结与思考
近期，随着各大Layer2项目纷纷空投或将要空投，包括Arbitrum, Optimism, zkSync, StarkWare等等市场头部，各种新的L2方案也纷纷融资和开启测试，这一赛道又重新进入了大众的视野并且引起讨论。从热度上来讲，相比于DeFi、NFT、gameFi等赛道，Layer2作为基础设施架构，技术门槛高并且没有那么明显的盈利空间，吸引的散户投资者相对较少。

不可否认的是，扩容的确是以太坊发展史上非常关键的组成部分。ETH2.0的发展主要就是转变为PoS的机制以及分片架构，而V神也多次表示了Layer2的发展处在以太坊2.0路线图的中心地位。gas的价格对于想进入加密世界的新人来说仍然是很高的门槛，在很多NFT开售时的gas war也非常恐怖。前段时间火热的Otherside铸造期间，gas费用一度达到了2e甚至3e，在一笔合约调用中就要花费几千美元是十分让人难以想象的存在，也让很多用户望而却步。作为区块链2.0核心的以太坊势必要解决这一问题，其未来的长时间规划也集中在扩容方面。


与此同时，众多的侧链新链崛起。侧链比如用户基数最广的Polygon, 新公链比如市场中最火的BSC，Solana，NEAR等等。大多数比对以太坊的重要优势就在于高TPS和低交易费。尽管单片化设计的区块链永远无法逃脱不可能三角的问题，但是在火热的市场中仍然能占有一席之地。Polygon, BSC上的众多链游、Solana上的稳定币和NFT，都是被市场认可的产物。关于新公链与以太坊扩容之争暂时还没有明确的答案，但是希望都能对于整个加密世界的扩张发展做出自己的贡献。
## 参考文献
1. [区块链 - 维基百科](https://zh.wikipedia.org/wiki/%E5%8C%BA%E5%9D%97%E9%93%BE)
2. [Bitcoin](https://bitcoin.org/en/)
3. [Home | ethereum.org](https://ethereum.org/en/)
4. [Coinbase - Buy and Sell Bitcoin, Ethereum, and more with trust](https://www.coinbase.com/price)
5. [OpenSea, the largest NFT market](https://opensea.io/)
6. [关于出块时间和区块大小的思考 | 为什么比特币不应该扩大区块？](https://www.jinse.com/blockchain/445934.html)
7. [数据库分片（Database Sharding)详解](https://zhuanlan.zhihu.com/p/57185574)
8. [以太坊分片概述](https://eth.wiki/sharding/ethresearch-sharding-compendium)
9. [Scaling | ethereum.org](https://ethereum.org/en/developers/docs/scaling/)
10. [sharding-roadmap | Ethereum Wiki](https://eth.wiki/sharding/sharding-roadmap)
11. [Layer2 终极指南 | 登链社区](https://www.learnblockchain.cn/article/3259)
12. [Layer2 | Plasma 框架](https://blog.csdn.net/chixiao5404/article/details/100729086)
13. [Plasma的陨落：是谁杀死了Plasma？](https://mp.weixin.qq.com/s/k_BOUJwPVC6YaXge91OiVQ)
14. [V神：rollup 不完全指南](https://zhuanlan.zhihu.com/p/356325643)
15. [EIP 4488](https://eips.ethereum.org/EIPS/eip-4488)
16. [百万富翁问题的一个简单解释](https://www.jianshu.com/p/5a220e95cee2)
17. [比较零知识证明算法zkSNARK,zkSTARKs,zkBoo,Sonic,BulletProofs](https://zhuanlan.zhihu.com/p/293203956)
18. [L2 - 深入理解OVM](https://learnblockchain.cn/article/1675)
19. [深入理解 Rollup上的虚拟机 OVM](https://learnblockchain.cn/article/1053)
20. [Optimistic Rollup vs. ZK Rollup 对比](https://learnblockchain.cn/article/738)
21. [Layer2赛道:短期OP，长期ZK](https://mp.weixin.qq.com/s/BcWuK1TCNvjGbeo9xq-A6w)
22. [zkRollup和Validium的区别：各自适合什么场景？](https://mp.weixin.qq.com/s/2sx19YmVFP_uDTGTFy-OQA)
23. [详解以太坊二层扩容方案StarkEx](https://www.qianba.com/news/p-427665.html)
24. [状态通道 | ethereum.org](https://ethereum.org/zh/developers/docs/scaling/state-channels/)
25. [Polygon(MATIC) Blockchain Explorer](https://polygonscan.com/)
26. [一文读懂「模块化」的以太坊时代](https://mp.weixin.qq.com/s?__biz=MzU2MDE2MDU3Mg==&mid=2247506755&idx=1&sn=cb55cd2104567fa13786e024f643a646&scene=21#wechat_redirect)
27. [展望“模块化”的区块链乐高世界](https://learnblockchain.cn/article/3082)
28. [EIP-4444: Bound Historical Data in Execution Clients](https://eips.ethereum.org/EIPS/eip-4444)
29. [EIP-4488: Transaction calldata gas cost reduction with total calldata limit](https://eips.ethereum.org/EIPS/eip-4488)
30. [Vitalik：以太坊终局之战](https://www.geekmeta.com/article/4142662.html)
31. [Plasma Contracts](http://plasma.io/plasma-contracts.html)